{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda3\\envs\\my_pytorch\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'G:\\Anaconda3\\envs\\my_pytorch\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "G:\\Anaconda3\\envs\\my_pytorch\\lib\\site-packages\\torch\\cuda\\__init__.py:80: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 8000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import fnmatch\n",
    "import os\n",
    "import os.path\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from train_eval import *\n",
    "import data_load\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========load the data==========\n",
      "labels matrix: torch.Size([895, 5])\n",
      "\n",
      "894.jpg done!\n",
      "\n",
      "samples matrix: torch.Size([895, 3, 200, 150])\n",
      "\n",
      "==========after processing==========\n",
      "labels matrix:torch.Size([767, 5])\n",
      "\n",
      "samples matrix:torch.Size([767, 3, 200, 150])\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "train_loader, cv_loader, test_loader = data_load.data_load()\n",
    "CNN_model = model.toho_CNN()\n",
    "CNN_model = CNN_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training -->     0/  614, loss --> 0.698\n",
      "training -->   256/  614, loss --> 0.695\n",
      "training -->     0/  614, loss --> 0.693\n",
      "training -->   256/  614, loss --> 0.693\n",
      "training -->     0/  614, loss --> 0.692\n",
      "training -->   256/  614, loss --> 0.691\n",
      "training -->     0/  614, loss --> 0.692\n",
      "training -->   256/  614, loss --> 0.684\n",
      "training -->     0/  614, loss --> 0.688\n",
      "training -->   256/  614, loss --> 0.685\n",
      "training -->     0/  614, loss --> 0.679\n",
      "training -->   256/  614, loss --> 0.685\n",
      "training -->     0/  614, loss --> 0.677\n",
      "training -->   256/  614, loss --> 0.679\n",
      "training -->     0/  614, loss --> 0.672\n",
      "training -->   256/  614, loss --> 0.669\n",
      "training -->     0/  614, loss --> 0.661\n",
      "training -->   256/  614, loss --> 0.658\n",
      "training -->     0/  614, loss --> 0.651\n",
      "training -->   256/  614, loss --> 0.657\n"
     ]
    }
   ],
   "source": [
    "for e in range(10):\n",
    "    model_train(CNN_model, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5482]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = plt.imread(\"./Dataset/raw_screenshots/Capture_01/582.jpg\")\n",
    "test = T.ToTensor()(test)\n",
    "CNN_model(torch.stack([test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4dbcc20bd42bae42a1c45c21a27db7c54bfeb7344c4316462725a59faf04af23"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('my_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
